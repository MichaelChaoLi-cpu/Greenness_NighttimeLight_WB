


%pwd


%cd ..


!dir





from glob import glob
from joblib import dump, load
import numpy as np
import pandas as pd
import random
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, KFold
from skopt import BayesSearchCV
from skopt.space import Real, Integer








### X and y
def getXandY(Output_Vari):
    y_list = glob("01_Data/*_y_" + Output_Vari + "*.csv")
    y = pd.read_csv(y_list[0], index_col=0)
    y = y.iloc[:,0].to_numpy()
    X_list = glob("01_Data/*_X_" + Output_Vari + "*.csv")
    X = pd.read_csv(X_list[0], index_col=0)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, 
                                                        random_state=1)
    return X_train, X_test, y_train, y_test











Output_Vari = "Happinessoverall"


X_train, X_test, y_train, y_test = getXandY(Output_Vari)


X_train.head()


X_train.describe()


X_train.columns


X_train.shape


X_test.shape


X = pd.concat([X_train, X_test])


X.shape


y = np.concatenate([y_train, y_test])


y.shape








param_space = {
    'n_estimators': Integer(100, 2000),
    'max_depth': Integer(3, 16),
    'max_samples': Real(0.5, 1.0),
    'min_samples_split':  Integer(2, 32)
}


rf_reg =RandomForestRegressor(n_jobs = 6)


class RandomRunNFoldsKFold(KFold):
    def __init__(self, n_splits=10, random_state=None, run_splits=3, **kwargs):
        super().__init__(n_splits=n_splits, shuffle=True, random_state=random_state, **kwargs)
        self.random_state = random_state
        self.actual_splits = run_splits  # Number of actual splits to use

    def split(self, X, y=None, groups=None):
        folds = list(super().split(X, y, groups))
        if self.random_state is not None:
            random.seed(self.random_state)
        selected_folds = random.sample(folds, self.actual_splits)
        for train_index, test_index in selected_folds:
            yield train_index, test_index

    def get_n_splits(self, X=None, y=None, groups=None):
        return self.actual_splits


rkfcv = RandomRunNFoldsKFold(n_splits=10, run_splits=3, random_state=42)


bayes_search = BayesSearchCV(
    estimator=rf_reg,
    search_spaces=param_space,
    n_iter=50,
    scoring='r2',
    cv=rkfcv,
    n_jobs = 1,
    n_points = 1,
    verbose=2,
    random_state=42,
    return_train_score = True
)


bayes_search.fit(X, y)


CV_result = bayes_search.cv_results_


pd.DataFrame(CV_result).sort_values(by='rank_test_score', ascending=True).head(10)


dump(bayes_search, 'Results/BayesSearch50iter.joblib')


pd.DataFrame(CV_result).sort_values(by='rank_test_score', ascending=True).to_csv('Results/BayesSearch50iter.csv')








bayes_search.best_params_


rf_reg_final =RandomForestRegressor(n_jobs = 6, **bayes_search.best_params_)
rf_reg_final.fit(X_train, y_train)


# Predictions
y_pred = rf_reg_final.predict(X_test)


y_pred


y_pred_categorical = np.where(y_pred < 1.5, 1,
                       np.where(y_pred < 2.5, 2,
                         np.where(y_pred < 3.5, 3,
                           np.where(y_pred < 4.5, 4, 5))))

y_pred_categorical


r2_score(y_test, y_pred_categorical)


from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_test, y_pred_categorical)



